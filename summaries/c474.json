{"id":"c474","number":2954,"headline":{"en":"Audio segmentation","da":"Lydsegmentering"},"content":{"en":"Audio segmentation: Researchers have developed algorithms that can classify and segment audio content based on type or speaker identity, improving tasks such as speech recognition and transcription. These algorithms use neural network models with regularizers to enhance performance in noisy conditions, discriminate between speech and music segments, and estimate speech rate without requiring automatic transcription. The algorithms also improve phonetic segmentation, phoneme recognition, and speech signal analysis, offering potential advancements in various applications such as speech synthesis and audio classification.","da":"Lydsegmentering: Forskere har udviklet algoritmer, der kan klassificere og segmentere lydindhold baseret på type eller taleridentitet, hvilket forbedrer opgaver som talegenkendelse og transskription. Disse algoritmer bruger neurale netværksmodeller med regularisatorer til at forbedre ydeevnen i støjfyldte omgivelser, skelne mellem tale og musiksegmenter og estimere taltakt uden at kræve automatisk transskription. Algoritmerne forbedrer også fonetisk segmentering, fonemgenkendelse og talestyrkesignal-analyse og tilbyder potentielle fremskridt inden for forskellige anvendelser som talesyntese og lydklassifikation."},"bots":{"critic":{"en":null,"da":null},"potential":{"en":null,"da":null}}}