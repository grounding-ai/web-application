{"id":"c2135","number":2698,"headline":{"en":"Audio-visual tracking","da":"Audio-visuel sporing"},"content":{"en":"Audio-visual tracking: Researchers have been exploring how audio and video data can be combined to track people in videoconferencing environments. They have developed algorithms, such as a particle-filter based tracking framework, that can efficiently and robustly fuse audio and visual information for speaker tracking. These algorithms have shown promise in improving tracking performance and robustness, and could potentially be used to track multiple speakers and localize targets in cluttered environments.","da":"Audio-visuel sporing: Forskere har undersøgt, hvordan lyd- og videodata kan kombineres for at spore personer i videokonferencesammenhænge. De har udviklet algoritmer, såsom en partikel-filter baseret sporingsramme, der effektivt og robust kan fusionere lyd- og visuel information til sporing af talere. Disse algoritmer har vist lovende resultater i forbedring af sporingsydelse og robusthed og kan potentielt bruges til at spore flere talere og lokalisere mål i rodede miljøer."},"bots":{"critic":{"en":null,"da":null},"potential":{"en":null,"da":null}}}